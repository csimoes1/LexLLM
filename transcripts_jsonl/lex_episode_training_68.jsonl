{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>a shorter game than your organism. Cancer is an organism playing a shorter game than the regular organism. Because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with a situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. Ideally, you want to, I think, build agents that play the longest possible games. The longest possible games is to keep entropy at bay as long as possible, by doing interesting stuff.<|eot_id|><|start_header_id|>assistant<|end_header_id|>The following is a conversation with Joscha Bach, his third time on this podcast. Joscha is one of the most brilliant, and fascinating minds in the world, exploring the nature of intelligence, consciousness, and computation. He's one of my favorite humans to talk to about pretty much anything and everything. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. Now, dear friends, here's Joscha Bach. You wrote a post about levels of lucidity. \"As we grow older, it becomes apparent that our self-reflexive mind is not just gradually accumulating ideas about itself, but that it progresses in somewhat distinct stages.\" There are seven of the stages. Stage one, reactive survival (infant). Stage two, personal self (young child). Stage three, social self (adolescence, domesticated adult). Stage four is rational agency (self-direction). Stage five is self-authoring, that's full adult. You've achieved wisdom, but there's two more stages. Stage six is enlightenment, stage seven is transcendence. Can you explain each, or the interesting parts of each of these stages, and what's your sense why there are stages of this, of lucidity as we progress through life in this too short life?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>tasked, is building a world model, and also an initial model of the self. But mostly, it's building a game engine in the brain that is tracking sensory data, and uses it to explain it. In some sense, you could compare it to a game engine like Minecraft or so, colors and sounds. People are all not physical objects. They're creation of our mind at a certain level. Of course, screening models that are mathematical that use geometry, and that use manipulation of objects, and so on to create scenes in which we can find ourselves, and interact with them.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Minecraft?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>a group. It's basically this thing that when you are playing in a team, for instance, you don't notice yourself just as a single node that is reaching out into the world, but you're also looking down. You're looking down from this entire group, and you see how this group is looking at this individual, and everybody in the group is, in some sense, emulating this group spirit to some degree. In this state, people are forming their opinions by assimilating them from this group mind. They basically gain the ability to act a little bit like a hive mind.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But are you also modeling the interaction of how opinion shapes and forms through the interaction of the individual nodes within the group?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah. Basically, the way in which people do it in this stage is that they experience what are the opinions of my environment. They experience the relationship that they have to their environment, and they resonate with people around them, and get more opinions through this interaction to the way in which they relate to others. At stage four, you basically understand that stuff is true and false independently, what other people believe, and you have agency over your own beliefs. In that stage, you basically discover epistemology, the rules about determining what's true and false.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You start to learn how to think?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>you always control. If you are a nerd like me, you often have to skip stage three, because you'd like the intuitive empathy with others. Because in order to resonate with a group, you need to have a quite similar architecture. If people are wired differently, then it's hard for them to resonate with other people, and basically have empathy, which is not the same as compassion, but it is a shared perceptual mental state. Empathy happens not just via inference about the mental states of others, but it's a perception of what other people feel, and where they're at.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Can't you not have empathy while also not having a similar architecture, cognitive architecture as the others in the group?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I think, yes. I experienced that too. But you need to build something that is like a meta architecture. You need to be able to embrace the architecture of the other to some degree, or find some shared common ground. It's also this issue that, if you are a nerd nomis, often people, basically neurotypical people have difficulty to resonate with you. As a result, they have difficulty understanding you, unless they have enough wisdom to feel what's going on there.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, isn't the whole process of the stage three to figure out the API to the other humans that have different architecture, and you yourself publish public documentation for the API that people can interact with for you? Isn't this the whole process of socializing?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>My experience as a child growing up was that I did not find any way to interface with the stage-three people, and they didn't do that with me, so took me-<|eot_id|><|start_header_id|>assistant<|end_header_id|>Did you try?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>in the world. There was basically nobody I could connect to. I remember, there was one moment in all these years, where I was in... There was a school exchange, and it was a Russian boy, a kid from the Russian garrison stationed in Eastern Germany who visited our school, and we played a game of chess against each other, and we looked into each other's eyes, and we sat there for two hours playing this game of chess. I had the impression, this is the human being, he understands what I understand, we didn't even speak the same language.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I wonder if your life could have been different if you knew that it's okay to be different, to have a different architecture, whether accepting that the interface is hard to figure out, it takes a long time to figure out and it's okay to be different. In fact, it's beautiful to be different.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It was not my main concern. My main concern was mostly that I was alone. It was not the so much the question, is it okay to be the way I am? I couldn't do much about it, so I had to deal with it. But my main issue was that I was not sure if I would ever meet anybody growing up that I would connect to at such a deep level that I would feel that I could belong.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So there's a visceral, undeniable feeling of being alone?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. I noticed the same thing when I came into the math school that I think at least half, probably two thirds of these kids were severely traumatized as children growing up, and in large part, due to being alone, because they couldn't find anybody to relate to.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Don't you think everybody's alone, deep down?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No.<|eot_id|><|start_header_id|>assistant<|end_header_id|>No.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I'm not alone.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Fair enough.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I'm not alone anymore. It took me some time to update, and to get over the trauma time and so on, but I felt that in my 20s, I had lots of friends, and I had my place in the world, and I had no longer doubts that I would never be alone again.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Is there some aspect to which we're alone together? You don't see a deep loneliness in inside yourself still?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No. Sorry.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Okay. That's the nonlinear progression through the stages, I suppose. You caught up on stage three at some point.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Correct. We're at stage four, and so basically I find that many nerds jump straight into stage four, bypassing stage three.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do they return to it then, later?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah, of course. Sometimes, they do. Not always.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Their question is basically, do you stay a little bit autistic, or do you catch up? I believe you can catch up. You can build this missing structure, and basically experience yourself as part of a group, learn intuitive empathy, and develop the sense, this perceptual sense of feeling what other people feel. Before that, I could only basically feel this when I was deeply in love with somebody, and we synced.<|eot_id|><|start_header_id|>assistant<|end_header_id|>There's a lot of friction to feeling that way, it's only with certain people, as opposed to it comes naturally?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's frictionless.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>But this is something that basically later, I felt, started to resolve itself for me to a large degree.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What was the trick?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>In many ways, growing up, and paying attention. Meditation did help. I had some very crucial experiences in getting close to people, building connections, and cuddling a lot in my student years.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Really, paying attention to the what is it, to the feeling another human being fully.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>which you can be safe, and can experiment, and touch a lot, and be close to somebody a lot. Over time, basically at some point, you realize, oh, it's no longer that I feel locked out, but I feel connected, and I experience where somebody else is at. Normally, my mind is racing very fast at a high frequency, so it's not always working like this. Sometimes works better, sometimes it works less, but also don't see this as a pressure. It's more, it's interesting to observe myself which frequency I'm at, and at which mode somebody else is at.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. Man, the mind is so beautiful in that way. Sometimes, it comes so natural to me, so easy to pay attention, pay attention to the world fully, to other people fully, and sometimes, the stress over silly things is overwhelming. It's so interesting that the mind is that rollercoaster in that way.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>At stage five, you discover how identity is constructed.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Self authoring.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Realize that your values are not terminal, but they're instrumental to achieving a world that you like, and aesthetics that you prefer. The more you understand this, the more you get agency over how your identity is constructed, and you realize that identity and interpersonal interaction is a costume, and you should be able to have agency over that costume, right? It's useful to be a costume, it tells something to others, and it allows to interface in roles. But being locked into this is a big limitation.<|eot_id|><|start_header_id|>assistant<|end_header_id|>The word costume implies that it's fraudulent in some way. Is costume a good word for you, like we present ourselves to the world?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>working in a bank, or if you are trying to get startup funding from a VC in Switzerland, then you dress up in a particular way. This is mostly to show the other side that you are willing to play by the rules, and you understand what the rules are. But there is something deeper when you are at Burning Man, your costume becomes self-expression, and there is no boundary to the self-expression. You're basically free to wear what you want to express other people, what you feel like this day, and what kind of interactions you want to have.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Is the costume a projection of who you are?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>That's very hard to say, because the costume also depends on what other people see in the costume. This depends on the context that the other people understand, so you have to create something if you want to, that is legible to the other side and that means something to yourself.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do we become prisoners of the costume, prisoner everybody expects us to?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Some people do. But I think that once you realize that you wear a costume at Burning Man, a variety of costumes, realize that you cannot not wear a costume.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Right. Basically, everything that you wear, and present to others is something that is, to some degree, in addition to what you are deep inside.<|eot_id|><|start_header_id|>assistant<|end_header_id|>This stage in parentheses, you put full adult, wisdom. Why is this full adult? Why would you say this is full, and why is it wisdom?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It does allow you to understand why other people have different identities from yours, and it allows you to understand that the difference between people who vote for different parties, and might have very different opinions and different value systems, is often the accident of where they're born, and what happened after that to them, and what traits they got before they were born. At some point, you realize the perspective, where you understand that everybody could be you in a different timeline, if you just flip those bits.<|eot_id|><|start_header_id|>assistant<|end_header_id|>How many costumes do you have?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't count, but in-<|eot_id|><|start_header_id|>assistant<|end_header_id|>More than one?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah, of course.<|eot_id|><|start_header_id|>assistant<|end_header_id|>How easy is it to do costume changes throughout the day?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's just a matter of energy, and interest. When you are wearing your pajamas, and you switch out of your pajamas into, say, a work short and pants, you're making a costume change, right? If you are putting on a gown, you're making a costume change.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You could do the same with personality?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>you're presenting yourself at work, you develop a sub-personality for this. The social persona for many people is, in some sense, a puppet that they're playing like a marionette. If they play this all the time, they might forget that there is something behind this, there's something what it feels like to be in your skin. I guess, it's very helpful if you're able to get back into this. For me, the other way around is relatively hard for me. It's pretty hard to learn how to play consistent social roles. For me, it's much easier just to be real.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Mm-hmm. Or not real, but to have one costume?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>interaction you would want to have with them. You get much earlier into Media Express, and I believe it's regrettable that we do not use the opportunities that we have, with custom-made clothing now, to wear costumes that are much more stylish, that are much more custom-made, that are not necessarily part of a fashion in which you express, which you knew you're part of, and how up-to-date you are. But you also express how you are as an individual, and what you want to do today, and how you feel today, and what you intend to do about that.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, isn't it easier now in a digital world to explore different costumes? I mean, that's the idea with virtual reality, that's the idea. Even with Twitter, in two-dimensional screens, you can swap all costumes. You could be as weird as you want, it's easier. For Burning Man, you have to order things, you have to make things, you have to... It's more effort to put on your-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's even better if you make them yourself.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Sure. But it's just easier to do digitally, right?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's not about easy. It's about how to get it right.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Sure.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>For me, the first Burning Man experience, I got adopted by a bunch of people in Boston who dragged me to Burning Man, and we spent a few weekends doing costumes together. That was an important part of the experience, where the camp bonded, that people got to know each other, and we basically grew into the experience that we would have later.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So the extraterrestrial prince is based on a true story?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I can only imagine what that looks like, Joscha.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Okay.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Stage six.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>personal self, but you observe the personal self from the outside, and you notice it's a representation. You might also notice that the world that is being created as the representation is not, then you might experience that I am the universe, I'm the thing that is creating everything. Of course, what you're creating is not quantum mechanics, and the physical universe. What you're creating is this game engine that is updating the world, and you're creating your valence, your feelings, and all the people inside of that world, including the person that you identify with yourself in this world.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Are you creating the game engine, or are you noticing the game engine?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>You notice how you're generating the game engine. I mean, when you are dreaming at night, you can... If you have a lucid dream, you can learn how to do this deliberately, and in principle, you can also do it during the day. The reason why we don't get to do this from the beginning, and why we don't have agency of our feelings right away is because we would game it, before we have the necessary amount of wisdom to deal with creating this dream that we are in.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You don't want to get access to cheat codes too quickly, otherwise you won't enjoy the game.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Stage five is already pretty rare, and stage six is even more rare. You most basically find this mostly with advanced Buddhist meditators and so on, that dropping into this stage, and can induce it at will, and spend time in it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Stage five requires a good therapist, stage six requires a good Buddhist spiritual leader?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>with this. For some people, this doesn't work, and they're forced to build more agency over their rational beliefs than this, and construct their norms rationally, and so they go to this level. Stage seven is something that is more or less hypothetical. That would be the stage in which, it's basically a trans-humanist stage in which you understand how you work, in which the mind fully realizes how it's implemented, and can also, in principle, enter different modes in which it could be implemented. That's the stage that, as far as I understand, is not open to people yet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Oh, but it is possible through the process of technology.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>about the algorithmic bias, and the model that it picks up, because if there's something wrong with this bias, the AI ultimately will prove it. At some point, we'll gather there that it makes mathematic proofs about reality, and then it will figure out what's true and what's false. But you're still worried that AI might turn you into paperclips, because it might have the wrong values, right? If it's set up through a wrong function that controls its direction in the world, then it might do something that is completely horrible, and there's no easy way to fix it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So that's more like a stage four rationalist worry?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>within certain temporal frames. The other thing is that it probably needs to have some kind of transcendental orientation, building shared agency, in the same way as we do when we are able to enter with each other into non-transactional relationships. I find that's something that, because the stage five is so rare, is missing in much of the discourse. I think that we need, in some sense, focus on how to formalize love, how to understand love, and how to build it into the machines that we are currently building, and that are about to become smarter than us.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, I think this is a good opportunity to try to sneak up to the idea of enlightenment. You wrote a series of good tweets about consciousness, and panpsychism. Let's break it down. First you say, I suspect the experience that leads to the panpsychism syndrome of some philosophers, and other consciousness enthusiasts represents the realization that we don't end at the self, but share a resonant universe representation with every other observer coupled to the same universe. This actually, eventually leads us to a lot of interesting questions about AI, and AGI. But let's start with this representation. What is this resonant universe representation, and what do you think? Do we share such a representation?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>like a few 100 milliseconds. There's a lot of stuff happening in that time, where the signal is passing through your brain, including in the brain itself. Nothing in the brain is assuming that stuff happens simultaneously, everything in the brain is working in a paradigm, where the world has already moved on, when you are very ready to do the next thing to your signal, including the signal processing system itself. It's quite different paradigm than the one in our digital computers, where we currently assume that your GPU or CPU is pretty much globally in the same state.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You mentioned there the non-dual state, and say that some people confuse it for enlightenment.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What's the non-dual state?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>There is a state in which you notice that you are no longer a person, and instead, you are one with the universe.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That speaks to the resonance.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. But this one with the universe is, of course, not accurately modeling that you are indeed some God entity, or indeed the universe is becoming aware of itself, even though you get this experience. I believe that you get this experience, because your mind is modeling the fact that you are no longer identified with the personal self in that state, but you have transcended this division between the self model and the wealth model, and you're experiencing yourself as your mind as something that is representing a universe.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But that's still part of the model?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. It's inside of the model, still. You are still inside of patterns that are generated in your brain, and in your organism. What you are now experiencing is that you're no longer this personal self in there, but you are the entirety of the mind, and its contents.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Why is it so hard to get there?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>A lot of people who get into the state think this, or associate it with enlightenment. I suspect, it's a favorite training goal for a number of meditators. But I think that enlightenment is, in some sense, more mundane, and it's a step further, or sideways. It's the state where you realize that everything is a representation.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. You say enlightenment is a realization of how experience is implemented.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. Basically, you notice at some point that your qualia can be deconstructed.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Reverse engineered, what? Almost like a schematic of it.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>at your face for a few hours in the mirror, or for a few minutes. At some point, it'll look very weird, because you notice that there's actually no face, you will start unseeing the face, what you see is the geometry. And then you can disassemble the geometry, and realize how that geometry is being constructed in your mind. You can learn to modify this. Basically, you can change these generators in your own mind to shift the face around, or to change the construction of the face, to change the way in which the features are being assembled.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Why don't we do that more often? Why don't we start really messing with reality, without the use of drugs or anything else? Why don't we get good at this kind of thing, intentionally?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Oh, why should you? Why would you want to do that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Because you can morph reality into something more pleasant for yourself, just have fun with it.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah. That is probably what you shouldn't be doing, right? Because outside of your personal self, this outer mind is probably a relatively smart agent, and what you often notice is that you have thoughts about how you should live, but you observe yourself doing different things, and having different feelings. That's because your outer mind doesn't believe you, and doesn't believe your rational thoughts.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, then can't you just silence the outer mind?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>an underlying system that is looking at your rational thoughts, and then tells you, no, you're still missing something. Your gut feeling is still saying something else. This can be, for instance, you find a partner that looks perfect, or you find a deal, when you build a company or whatever, that looks perfect to you and yet, at some level, you feel something is off. You cannot put your finger on it, and the more you reason about it, the better it looks to you. But the system that is outside still tells you, no, no, you're missing something.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That system is powerful?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>People call this intuition, right? Intuition is this unreflected part of your attitude, composition, and computation, where you produce a model of how you relate to the world, and what you need to do in it, and what you can do in it, and what's going to happen. That is usually deeper, and often more accurate than your reason.<|eot_id|><|start_header_id|>assistant<|end_header_id|>If we look at this, as you write in the tweet, if we look at this more rigorously as a sort of, take the panpsychist idea more seriously, almost as a scientific discipline, you write that quote fascinatingly, that panpsychist interpretation seems to lead to observations of practical results to a degree that physics fundamentalists might call superstitious. Reports of long distance tele telepathy, and remote causation are ubiquitous in the general population. \" I'm not convinced,\" says Joscha Bach, \"that establishing the empirical reality of telepathy would force an update of any part of serious academic physics. But it could trigger an important revolution in both neuroscience and AI, from a circuit perspective to a coupled complex resonator paradigm.\" Are you suggesting that there could be some rigorous mathematical wisdom to panpsychist perspective on the world?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>manage to dissolve the division between personal self and mind that you establish as an infant when you construct a personal self and transcend it again and understand how it works. But there is something deeper that you feel that you're also sharing a state with other people, that you have an experience in which you notice that your personal self is moving into everything else, that you basically look out of the eyes of another person, that every agent in the world that is an observer is in some sense you. We forget that we are the same agent.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So is it that we feel that or do we actually accomplish it? So is telepathy possible? Is it real?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>few bits out of the ether to figure out what this person is doing. Or maybe it's also when you are very close to somebody and you become empathetic with them. What happens that is that you go into a resonance state with them, right? Similar to when people go into a seance and they go into a trance state and they start shifting a ouija board around on the table. I think what happens is that their minds go by their nervous systems into a resonance state in which they basically create something like a shared dream between them.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Physical closeness or closeness broadly defined?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>the tasks of a neuron can be fulfilled by other cells as well that can send different typed chemical messages and physical messages to their adjacent cells and learn when to do this and when not, make this conditional and become universal function approximators. The only thing that they cannot do is telegraph information over axons very quickly, over long distances. So neurons in this perspective are especially adapted telegraph cell that has evolved, so we can move our muscles very fast, but our body is in principle able to also make models of the world just much, much slower.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's interesting though that at this time, at least in human history, there seems to be a gap between the tools of science and the subjective experience that people report like you're talking about with telepathy, and it seems like we're not quite there?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No, I think that there is no gap between the tools of science and telepathy. Either it's there or it's not, and it's an empirical question, and if it's there, we should be able to detect it in a lab.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So why is there not a lot of Michael Levin's walking around?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>is first of all radical locality, which means everything is decided locally from the perspective of an individual cell. The individual cell is the agent. And the other one is coherence. Basically, there needs to be some criterion that determines how these cells are interacting in such a way that order emerges on the next level of structure, and this principle of coherence of imposing constraints that are not validated by the individual parts, and lead to coherence structure to basically transcend an agency where you form an agent on the next level of organization, is crucial in this perspective.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's so cool that radical locality leads to the emergence of complexity at the higher layers.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And I think what Mike Levin is looking at is nothing that is outside of the realm of science in any way. It's just that he is a Paradigmatic thinker who develops his own paradigm, and most of the neuroscientists are using a different paradigm at this point, and this often happens in science that a field has a few paradigms in which people try to understand reality and build concepts and make experiments.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You're kind of one of those type of paradigmatic thinkers. Actually, if we can take a tangent on that, once again, returning to the biblical verses of your tweets. \"You're right, my public explorations are not driven by audience service, but by my lack of ability for discovering, understanding or following the relevant authorities. So I have to develop my own thoughts. Since I think autonomously these thoughts cannot always be very good.\" That's you apologizing for the chaos of your thoughts or perhaps not apologizing, just identifying.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But let me ask the question. Since we talked about Michael Levin and yourself who I think are very kind of radical, big, independent thinkers, can we reverse engineer your process of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced by what is it stage three?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>the system can experience anything, how motivation emerges in the mind were not being answered by the authorities that I met and the schools that were around. And instead I found that with individual thinkers that had useful ideas that sometimes were good, sometimes were not so good. Sometimes were adopted by a large group of people, sometimes were rejected by large groups of people, but for me it was much more interesting to see these minds as individuals. And in my perspective, thinking is still something that is done not in groups that has to be done by individuals.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So that motivated you to become an individual thinker yourself?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>works or how thinking works or what thinking even is or what feelings are and how they're implemented and so on. So to figure out this out, I had to take a lot of ideas from individuals and then try to put them together in something that works for myself. And on one hand I think it helps if you try to go down and find first principles on which you can recreate how thinking works, how languages work, what representation is, but the representation is necessary, how the relationship between a representing agent and the world works in general.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But how do you escape the influence? Once again, the pressure of the crowd, whether it's you in responding to the pressure or you being swept up by the pressure. If you even just look at Twitter, the opinions of the crowd?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>authority, I have respect for what an individual is accomplishing or have respect for mental firepower or so, but it's not that I meet somebody and get drawn and unable to speak or when a large group of people has a certain idea that is different from mine, I don't necessarily feel in intimidated, which has often been a problem for me in my life because I lack instincts that other people develop at a very young age and that help with their self-preservation in a social environment. So I had to learn a lot of things the hard way.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. So is there a practical advice you can give on how to think paradigmatically, how to think independently or because you've said I had no choice, but I think to a degree you have a choice because you said you want to be productive and I'm thinking independently is productive if what you're curious about is understanding the world, especially when the problems are very new and open. And so it seems like this is a active process. Who can choose to do that? We can practice it.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I can make geometry and counting and all the number games that we are playing in our life, and on the other hand, I felt that I learned a lot of this while I was programming as a child. When you start out with a computer like a Commodore 64 which doesn't have a lot of functionality, it's relatively easy to see how a bunch of relatively simple circuits are just basically performing hashes between bit patterns and how you can build the entirety of mathematics and computation on top of this and all the representational languages that you need.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Man, Commodore 64 could be one of the sexiest machines ever built if I say so myself. If we can return to this really interesting idea that we started to talk about with Pan-psychism.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Sure.<|eot_id|><|start_header_id|>assistant<|end_header_id|>And the complex resonated paradigm and the verses of your tweets, you write, \"Instead of treating eyes, ears, and skin as separate sensory systems with fundamentally different modalities, we might understand them as overlapping aspects of the same universe coupled at the same temporal resolution and almost inseparable from a single share resonant model. Instead of treating mental representations as fully isolated between minds, the representations of physically adjacent observers might directly interact and produce causal effects through the coordination of the perception and behavioral of world modeling observers. So the modalities, the distinction between modalities, let's throw that away. The distinction between the individuals, let's throw that away.\" So what does this interaction representations look like?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that you're hearing have an influence on how you interpret some of the visual features, and so these modalities are not separate in your mind. They do are merged at some fundamental level where you are interpreting the entire scene that you're in. And your own interactions in the scene are also not completely separate from the interactions of the other individual in the scene, but there is some resonance that is going on where we also have a degree of shared mental representations and shared empathy due to being in the same space and having vibes between each other.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Vibes. So the question though is how deeply intertwined is this multi-modality, multi-agent system? How, I mean this is going to the telepathy question without the woo woo meaning of the word telepathy, is like how? What's going on here in this room right now?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>So if telepathy would work, how could it work?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>on the communication between the cells of the tree and send its own signals to the tree and vice versa, the tree might be able to send information to the fungus because after all, how would they pull a viable firewall if that other organism is sitting next to them all the time and it's never moving away, so they will have to get along, and over a long enough timeframe the networks of roots in the forest and all the other plants that are there and the fungi that are there might be forming something like a biological internet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But the question there is do they have to be touching? Is biology at a distance, possible?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Of course you can use any kind of physical signal. You can use sounds, you can use electromagnetic waves that are integrated over many styles. It's conceivable that across distances there are many kinds of information pathways, but also our planetary surface is pretty full of organisms, full of cells.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So everything is touching everything else.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>link into this biological internet. Not necessarily at the speed of our nervous system, but maybe at the speed of our body, and make some kind of subconscious connection to the world where we use our body as an antenna into biologic information processing. Now these ideas are completely speculative. I don't know if any of that is true, but if that was true, and if you want to explain telepathy, I think it's much more likely that such that telepathy could be explained using such mechanisms rather than discovered quantum processes that would break the standard model of physics.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Could they be undiscovered processes that don't break?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah, so if you think about something like an internet in the forest, that is something that is borderline is covered there basically a lot of scientists would point out that they do observe that plants are communicating the forest, so wood networks and send information for instance, warn each other about new pests entering the forest and things are happening like this. So basically there is communication between plants and fungi that has been observed.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, it's been observed but we haven't plugged into it, so it's like if you observe humans, they seem to be communicating with a smartphone thing, but you don't understand how smartphone works and how the mechanism of the internet works, but we're like maybe it's possible to really understand the full richness of the biological internet that connects us.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>digital computers are. So there is a different base protocol layer that would emerge over the biological structure, if such a thing would be happening, and again, I'm not saying here that telepathy works and not saying that this is not woo, but what I'm saying is I think I'm open to a possibility that we see that a few bits can be traveling long distance between organisms using biological information processing in ways that we are not completely aware of right now, and that are more similar to many of the stories that were completely normal for our ancestors.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well this kind of interacting, intertwined representations takes us to the big ending of your tweet series. You write, \"I wonder if self-improving AGI might end up saturating physical environments with intelligence to such a degree that isolation of individual mental states becomes almost impossible and the representations of all complex self-organizing agents merge permanently with each other.\" So that's a really interesting idea. This biological network, life network, gets so dense that it might as well be seen as one. That's an interesting... What do you think that looks like? What do you think that saturation looks like? What does it feel like?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>at AGI research and can take over in building the next generation, but it fully understands how it works and how it's being implemented, and also of course understands how computation works in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI is likely to virtualize itself into any environment that can compute, so it's not breaking free from the silicon substrate and is going to move into the ecosystems, into our bodies, our brains, and it's going to merge with all the agency that it finds there.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>is saturated with modeling compute, where basically you almost every grain of sand could be part of computation that is at some point being started by the AI, you could find yourself in a situation where you cannot escape this shared representation anymore, and where you indeed notice that everything in the world has one shared resonant model of everything that's happening on the planet. And you notice which part you are in this thing, and you become part of a very larger almost holographic mind in which all the parts are observing each other and form a coherent whole.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So you lose the ability to notice yourself as a distinct entity.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>a hundred layers. This would not be stable on biological neurons, and so instead we start with some colonizing principle in which a part of the mental representations form a notion of being a self-reflexive absorber that is imposing coherence on its environment and this spreads until the boundary of your mind. And if that boundary is no longer clear cut because AI is jumping across substrates, it would be interesting to see what a global mind would look like that is basically producing a globally coherent language of thought, and is representing everything from all the possible vantage points.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That's an interesting world.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>but if you combine this with the notion that the systems are physically interacting to the point where their representations are merging and interacting with each other, you would literally implement something like this. It would still be a representational state where you would not be one with physics itself. It would still be cross-grained, would still be much slower than physics itself, but it would be a representation in which you become aware that you're part of some global information processing system like thought and a global mind, and a conscious thought that coexisting with many other self-reflexive thoughts.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Just I would love to observe that from a video game design perspective, how that game looks.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Maybe you will after we build AGI and it takes over.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But would you be able to step away, step out at the whole thing, just watch the way we can now? Sometimes when I'm at a crowded party or something like this, you step back and you realize, all the different costumes, all the different interactions, all the different computation that all the individual people are at once distinct from each other and at once all the same, part of the same.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>But it's already what we do. We can have thoughts that are integrative and we have thoughts that are highly dissociated from everything else and experience themselves as separate.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But you want to allow yourself to have those thoughts. Sometimes you resist it.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I think that it's not normative. I want it's more descriptive. I want to understand the space of states that we can be in and that people are reporting and make sense of them. It's not that I believe that it's your job in life to get to a particular state and then you get a high score.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Or maybe you do. I think you're really against this high scoring thing. I kind of like that.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah, you're probably very competitive and I'm not.<|eot_id|><|start_header_id|>assistant<|end_header_id|>No, not competitive, like role playing games like Skyram, it's not competitive. There's a nice thing... There's a nice feeling where your experience points go up. You're not competing against anybody, but it's the world saying, \"You're on the right track. Here's a point.\"<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>That's the game thing. It's the game economy, and I found when I was playing games and was getting addicted to these systems, then I would get into the game and hack it. So I get control over the scoring system and would no longer be subject to it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So you're now no longer playing, you're trying to hack it.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't want to be addicted to anything. I want to be in charge. I want to have agency over what I do.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Addiction is the loss of control for you?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. Addiction means that you're doing something compulsively, and the opposite of freewill is not determinism, it's compulsion.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You don't want to lose yourself in the addiction to something nice? Addiction to love, to the pleasant feelings with humans experience?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No, I find this gets old. I don't want to have the best possible emotions, I want to have the most appropriate emotions. I don't want to have the best possible experience, I want to have an adequate experience that is serving my goals, the stuff that I find meaningful in this world.<|eot_id|><|start_header_id|>assistant<|end_header_id|>From the biggest questions of consciousness. Let's explore the pragmatic, the projections of those big ideas into our current world. What do you think about LLMs, the recent rapid development of large language models, of the AI world, of generative AI. How much of the hype is deserved and how much is not? And people should definitely follow your Twitter because you explore these questions in a beautiful, profound and hilarious way at times.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No, don't follow my Twitter, I already have too many followers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>block more than before, and I don't like this overall vibe shift. And right now it's still somewhat okay, so pretty much, okay, so I can go to a place where... ... pretty much okay, so I can go to a place where people work on stuff that I'm interested in, and there's a good chance that a few people in the room know me. There's no awkwardness. But when I get to a point where random strangers feel that they have to have an opinion about me one way or the other, I don't think I would like that.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Random strangers because of your, in their mind, elevated position?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. Basically, whenever you are in any way prominent or some celebrity, random strangers will have to have an opinion about you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>They forget that you're human too.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I mean, you notice this thing yourself, that the more popular you get, the higher the pressure becomes, the more winds are blowing in your direction from all sides. It's stressful and it does have a little bit of upside, but it also has a lot of downside.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I think it has a lot of upside, at least, for me, currently. At least, perhaps because of the podcast. Because most people are really good and people come up to me and they have love in their eyes and over a stretch of 30 seconds you can hug it out and you can just exchange a few words and you reinvigorate your love for humanity. That's an upside for a loner. I'm a loner. Because otherwise, you have to do a lot of work to find such humans. Here you are thrust into the full humanity, the goodness of humanity for the most part. Of course, maybe it gets worse as you become more prominent. I hope not. This is pretty awesome.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I have a couple handful, very close friends, and I don't have enough time for them, attention for them as it is. I find this very, very regrettable. Then there are so many awesome, interesting people that I keep meeting, and I would like to integrate them in my life, but I just don't know how because... But there's only so much time and attention. The older I get, the harder is to bond with new people in a deep way.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But can you enjoy... I mean, there's a picture of you I think with Roger Penrose and Eric Weinstein and a few others that are interesting figures. Can't you just enjoy random, interesting humans-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Very much.<|eot_id|><|start_header_id|>assistant<|end_header_id|>... for a short amount of time?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Also, I like these people. What I like is intellectual stimulation, and I'm very grateful that I'm getting it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Can you not be melancholy or maybe I'm projecting I hate goodbyes? Can we just not hate goodbyes and just enjoy the hello, take it in a person, take in their ideas, and then move on through life?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I think it's totally okay to be said about goodbyes because that indicates that there was something that you're going to miss.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But it's painful. Maybe that's one of the reasons I'm an introvert is I hate goodbyes.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>But you have to say goodbye before you say hello again.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I know. But that experience of loss, that mini loss, maybe that's a little death. Maybe I don't know. I think this melancholy feeling is just the other side of love, and I think they go hand in hand, and it's a beautiful thing. I'm just being romantic about it at the moment.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I'm not no stranger to melancholy and sometimes it's difficult to be alive. Sometimes it's just painful to exist.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But that there's beauty in that pain too. That's what melancholy feeling is. It's not negative. Melancholy doesn't have to be negative.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Can also kill you.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Well, we all die eventually. Now as we got through this topic, the actual question was about what your thoughts are about the recent development of large language models with ChatGPT.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Indeed.<|eot_id|><|start_header_id|>assistant<|end_header_id|>There's a lot of hype. Is some of the hype justified, which is, which isn't? What are your thoughts high level?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>and so on. Your language model can help you to fix those things. But this process is out of the box not automated yet. There is a management process that also needs to be done. There are some interesting developments BabyAGI and so on that are trying to automate this management process as well. I suspect that soon we are going to see a bunch of cognitive architectures where every module is in some sense a language model or something equivalent. Between the language models, we exchange suitable data structures, not English, and produce compound behavior of this whole thing.<|eot_id|><|start_header_id|>assistant<|end_header_id|>To do some of the \"prompt engineering\" for you. They create these cognitive architectures that do the prompt engineering and you're just doing the high, high-level meta prompt engineering.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that is closer to our brain, imagine that you would take a language model or a model like DELI that you use... For instance, this image-guided diffusion to approximate and camera image and use the activation state of the neural network to interpret the camera image, which in principle I think will be possible very soon. You do this periodically, and now you look at these patterns, how when this thing interacts with the world periodically look like as in time, and these time slices, they are somewhat equivalent to the activation state of the brain at a given moment.<|eot_id|><|start_header_id|>assistant<|end_header_id|>How is the actual brain different? Just the asynchronous craziness?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>direction it should shift its behavior. Once you have such an input, neurons become trainable, and you can train them to perform computations by exchanging messages with other neurons and parts of the signals that they're exchanging and parts of the computation that are performing are control messages that perform management tasks for other neurons and other cells also suspect that the brain does not stop at the boundary of neurons to other cells, but many adjacent cells will be involved intimately in the functionality of the brain and will be instrumental in distributing rewards and in imagining its functionality.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's fascinating to think about what those characteristics of the brain enable you to do that language models cannot do.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that a human nervous system could do this. For us, the world is only learnable because the adjacent frames are related and we can afford to discard most of that information during learning. We basically take only in stuff that makes us more coherent, not less coherent, and our neural networks are willing to look at data that is not making the neural network coherent at first, but only in the long run by doing lots and lots of statistics, eventually, patterns become visible and emerge. Our mind seems to be focused on finding the patterns as early as possible.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. Filtering early on, not later.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>and have all this knowledge available and being able to confabulate over it. Instead, we have a much, much smaller part of it that is more deliberately built. To me, it would be fascinating to think about how to build such systems. It's not obvious that they would necessarily be more efficient than us on a digital substrate, but I suspect that they might, so I suspect that the actual AGI that is going to be more interesting is going to use slightly different algorithmic paradigms or sometimes massively different algorithmic paradigms than the current generation of transformer-based learning system.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do you think it might be using just a bunch of language models like this? Do you think the current transformer-based large language models will take us to AGI?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>My main issue is I think that they're quite ugly and brutalist-<|eot_id|><|start_header_id|>assistant<|end_header_id|>Brutalist? Is that what you said?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. They are basically brute forcing the problem of thought. By training this thing with looking at instances where people have thought and then trying to deepfake that. If you have enough data, the deepfake becomes indistinguishable from the actual phenomenon, and in many circumstances, it's going to be identical.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Can you deepfake it till you make it? Can you achieve... What are the limitations of this? I mean, can you reason? Let's use words that are loaded.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>additional layers, and so on. Then the next day, it starts with a fresh database in the morning with fresh ice has integrated all this stuff. When you talk to people and you have strong disagreements about something, which means that in their mind they have a faulty belief or you have a faulty belief, there's a lot of dependencies on it. Very often, you will not achieve agreement in one session, but you need to sleep about this once or multiple times before you have integrated all these necessary changes in your mind. Maybe it's already somewhat similar, right?<|eot_id|><|start_header_id|>assistant<|end_header_id|>There's already a latency even for humans to update the model, retrain the model.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>so on. There is no reason to believe that the language models will necessarily run into some problem that will prevent them from becoming generally intelligent. But I don't know that. It's just I don't see proof that they wouldn't. My issue is I don't like them. I think that they're inefficient. I think that they use way too much compute. I think that given the amazing hardware that we have, we could build something that is much more beautiful than our own mind, and this thing is not as beautiful as our own mind despite being so much larger.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But it's a proof of concept.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's the only thing that works right now. It's not the only game in town, but it's the only thing that has this utility with so much simplicity. There's a bunch of relatively simple algorithms that you can understand in relatively few weeks that can be scaled up massively.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's the Deep Blue of chess playing. Yeah, it's ugly.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that it's in principle not doing anything that I could not do if I had Google at my disposal and I get all the resources from the internet and spend enough time on it. But this thing that I have an extremely autistic stupid intern in a way that is extremely good at drudgery, and I can offload the drudgery to the degree that I'm able to automate the management of the intern is something that is difficult for me to overhype at this point because we have not yet started to scratch the surface of what's possible with this.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But it feels like it's a tireless intern or maybe it's an army of interns. So you get to command these slightly incompetent creatures and there's an aspect because of how rapidly you can iterate with it. It's also part of the brainstorming, part of the inspiration for your own thinking. You get to interact with the thing. I mean, when I'm programming or doing any generational GPT, it's somehow is a catalyst for your own thinking. In a way, that I think an intern might not be.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>better programing language? Now I think that almost every serious computer scientist goes through a phase like this in their life. This question that is almost no longer relevant because what is different between the programming language is not what they let the computer do, but what they let you think about what the computer should be doing. Now the ChatGPT becomes an interface to this in which you can specify in many, many ways what the computer should be doing and ChatGPT or some other language model or combination of system is going to take care of the rest.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Allow you expand the realm of thought you're allowed to have when interacting with the computer. It sounds to me like you're saying there's basically no limitations. Your intuition says to what larger language-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't know of that limitation. When I currently play with it's quite limited. I wish that it was way better.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But isn't that your fault versus the large language model?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't know. Of course, it's always my fault. There's probably a way to make it lot better.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Is everything your fault? I just want to get you on the record saying.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Even though with hindsight I feel no. I sometimes wish I could have seen myself as part of my environment more and understand that a lot of people are actually seeing me and looking at me and are trying to make my life work in the same way as I try to help others. Making this switch to this level-three perspective is something that happened long after my level-four perspective in my life. I wish that I could have had it earlier. It's also not now that I don't feel like I'm complete, I'm all over the place. That's all.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Where's happiness in terms of stages is on three or four that you take that tangent?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>job to choose the environment that you thrive and to build it. Sometimes it's difficult to get the necessary strength and energy to do this and independence. The worst you feel, the harder it is. But it's something that we learn. It's also this thing that we are usually incomplete, right? I'm a rare mind, which means I'm a mind that is incomplete in ways that are harder to complete. For me, it might have been harder to initially to find the right relationships and friends that complete me to the degree that I become an almost functional human being.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Oh, man, the search space of humans that complete you is an interesting one, especially for Joscha Bach. That's an interesting... Because talking about brute-force search in chess, I wonder what that search tree looks like.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>to solve that task. A lot of problems in my life that I can conceptualize as software problems and the failure modes are bugs, and I can debug them and write software that take care of the missing functionality. But there is stuff that I don't understand well enough to and to use my analytical reasoning to solve the issue. Then I have to develop my intuitions and often I have to do this with people who are wiser than me. That's something that's hard for me because I'm not born with the instinct to submit to other people's wisdom.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What problems are we talking about? This is stage three love?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I found love was never hard.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What is hard then?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Fitting into a world that most people work differently than you and have different intuitions of what should be done.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Empathy?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>a child of an artist. In this place, it was mostly nature. Everything had intrinsic beauty and everything was built out of an intrinsic need for it to work for itself. Everything that my father created was something that he made to get the world to work for himself. I felt the same thing. When I come out into the world, and I am asked to submit to lots and lots of rules, I'm asking, okay, when I observe your stupid rules, what is the benefit? I see the life that is being offered as a reward, it's not attractive.<|eot_id|><|start_header_id|>assistant<|end_header_id|>When you were born and raised in extraterrestrial prints in a world full of people wearing suits, it's a challenging integration.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. But it also means that I'm often blind for the ways in which everybody is creating their own bubble of wholesomeness or almost everybody. People are trying to do it. For me, to discover this, it was necessary that I found people who had a similar shape of soul as myself. Basically, where I felt these are my people that treat each other in such a way as if they're around with each other for eternity.<|eot_id|><|start_header_id|>assistant<|end_header_id|>How long does it take you to detect the geometry, the shape of the soul of another human to notice that they might be one of your kind?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Sometimes it's instantly, and I'm wrong. Sometimes it takes a long time.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You believe in love at first sight, Joscha Bach?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. But I also noticed that I have been wrong. Sometimes I look at a person and I'm just enamored by everything about them. Sometimes this persists and sometimes it doesn't. I have the illusion that it much better at recognizing who people are as I grow older.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But that could be just cynicism. No.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No, It's not cynicism. It's often more that I'm able to recognize what somebody needs when we interact and how we can meaningfully interact. It's not cynical at all.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You're better at noticing.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes, I'm much better I think in some such circumstances at understanding how to interact with other people than I did when I was young.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That takes us to-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It doesn't mean that I'm always very good at it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That takes us back to prompt engineering of noticing how to be a better prompt engineer of an LLM. A sense I have is that there's a bottomless well of skill to become a great prompt engineer. It feels like it is all my fault whenever I fail to use ChatGPT correctly that I didn't find the right words.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>relationship to people, and it's necessary for me to write for myself because writing is not so much about producing an artifact that other people can use, but it's a way to structure your own thoughts and develop yourself. I think this idea that kids are writing their own essays with ChatGPT in the future is going to have this drawback that they miss out on the ability to structure their own minds via writing. I hope that the schools that our kids are in will retain the wisdom of understanding what parts should be automated and which ones shouldn't.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But at the same time, it feels like there's power in disagreeing with the thing that ChatGPT produces. I use it like that for programming. I'll see the thing it recommends, and then I'll write different code that disagree, and in the disagreement, your mind grows stronger.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>and manipulate them and so on. I don't know Swift. It was super helpful to have this thing that is writing stuff for me. Also, interesting that mostly it didn't work at first. I felt like I was talking to a human being who was trying to hack this on my computer without understanding my configuration very much. Also, making a lot of mistakes. Sometimes it's a little bit incoherent, so you have to ultimately understand what it's doing. It's still no other way around it, but I do feel it's much more powerful and faster than using Stack Overflow.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do you think GPTN can achieve consciousness?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that is emulating adjacent brain states that require a degree of self-reflection, it can also create a model of an observer that is reflecting itself in real-time and describe what that's like. While this model is the deepfake, our own consciousness is also as if it's virtual, right? It's not physical. Our consciousness is a representation of a self-reflexive observer that only exists in patterns of interaction between cells. It is not a physical object in the sense that exists in base reality, but it's really a representational object that develops its causal power only from a certain modeling perspective.<|eot_id|><|start_header_id|>assistant<|end_header_id|>It's virtual.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>something that the language models don't need to do. There is no causal need for the system to be conscious in the same way as we are. For me, it would be very interesting to experiment with this, to basically build a system like a CAT probably should be careful at first, build something that's small, that's limited resources that we can control, and study how systems notice a self-model, how they become self-aware in real-time. I think it might be a good idea to not start with the language model but to start from scratch using principles of self-organization.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Okay. Can you elaborate why you think that is so self-organization this... ... why you think that is? So, self-organization, this kind of radical legality that you see in the biological systems, why can't you start with a language model, what's your intuition?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>My intuition is that the language models that we are building are golems. They are machines that you give a task, and they're going to execute the task until some condition is met and there's nobody home. And the way in which nobody is home leads to that system doing things that are undesirable in a particular context.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>to the child. Or you have that thing writing a speech and it introduces errors in the speech that no human being would ever do if they're responsible. The system doesn't know who's talking to whom. There is no ground truth that the system is embedded into. And of course we can create an external tool that is prompting our language model always into the same semblance of ground truth, but it's not like the internal structure is causally produced by the needs of a being to survive in the universe, it is produced by imitating structure on the internet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah, but can we externally inject into it this coherent approximation of a world model that has to sync up?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>in history of AI, next-token prediction was not very high up. And there are some similarities like cognition as data compression is an odd trope, Solomonoff induction where you are trying to understand intelligence as predicting future observations from past observations, which is intrinsic to data compression. And predictive coding is a paradigm that there's boundary between neuroscience and physics and computer science, so it's not something that is completely alien, but this radical thing that you only do in next-token prediction and see what happens is something where most people, I think, were surprised that this works so well.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So simple, but is it really that much more radical than just the idea of compression, intelligence is compression?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>The idea that compression is sufficient to produce all the desired behaviors is a very radical idea.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But equally radical as the next token prediction?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's something that wouldn't work in biological organisms, I believe.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Biological organisms have something like next frame prediction for our perceptual system where we try to filter out principal components out of the perceptual data and build hierarchies over them to track the world. But our behavior ultimately is directed by hundreds of physiological and probably dozens of social and a few cognitive needs that are intrinsic to us, that are built into the system as reflexes and direct us until we can transcend them and replace them by instrumental behavior that relates to our higher goals.<|eot_id|><|start_header_id|>assistant<|end_header_id|>And it also seems so much more complicated and messy than next frame prediction, even the idea of frame seems counter biological.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>like simultaneity is necessary for many processes that happen in the brain. And you see the outcome of that by synchronized brainwaves, which suggests that there is indeed synchronization going on, but the synchronization creates overhead and this overhead is going to make the cells more expensive to run and you need more redundancy and it makes the system slower. So, if you can build a system in which the simultaneity gets engineered into it, maybe you have a benefit that you can exploit that is not available to the biological system and that you should not discard right away.<|eot_id|><|start_header_id|>assistant<|end_header_id|>You tweeted, once again, \"When I talk to ChatGPT, I'm talking to an NPC. What's going to be interesting, and perhaps scary, is when AI becomes a first person player.\" So, what does that step look like? I really like that tweet, that step between NPC to first person player. What's required for that? Is that kind of what we've been talking about, this kind of external source of coherence and inspiration of how to take the leap into the unknown that we humans do? Man's search for meaning, LLM's search for meaning.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I suspect, when they say this is the description of the creation of the physical universe by a supernatural being. I think this is literally a description of how in every mind a universe is being created as some kind of game engine by a creative spirit, our first consciousness that emerges in our mind even before we are born and that creates the interaction between organism and world. And once that is built and trained, the personal self is being created and we only remember being the personal self, we no longer remember how we created the game engine.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So, God in this view is the first creative mind in the early...<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's the first consciousness.<|eot_id|><|start_header_id|>assistant<|end_header_id|>In the early days, in the early months.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Of development<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that is not yourself that is producing this, it's your mind that does it. So, there is an outer mind that basically is an agent that determines who you are with respect to the world, and while you are stuck being that personal self in this world, until you get to stage six to destroy the boundary. And we all do this, I think, earlier in small glimpses, and maybe we're sometimes we can remember what it was like when we were a small child and get some glimpses into how it's been, but for most people that rarely happens.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Just glimpses. You tweeted, \"Suffering results for one part of the mind failing at regulating another part of the mind. Suffering happens at an early stage of mental development. I don't think that superhuman AI would suffer.\" What's your intuition there?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>The philosopher Thomas Metzinger is very concerned that the creation of superhuman intelligence would lead to superhuman suffering.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And so, he's strongly against it. And personally, I don't think that this happens because suffering is not happening at the boundary between ourself and the physical universe. It's not stuff on our skin that makes us suffer. It happens at the boundary between self and world, and the world here is the world model, it's the stuff that is created by your mind.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But that's all-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>being created and rerouted and improve the regulation. And a lot of people get there, if you are a monk who is spending decades reflecting about how their own psyche works, you can get to the point where you realize that suffering is really a choice and you can choose how your mind is set up. And I don't think that AI would stay in the state where the personal self doesn't get agency or this model, what the system has about itself, it doesn't get agency how it's actually implemented. It wouldn't stay in that state for very long.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So, it goes through the stages real quick, the seven stages, it's going to go to enlightenment real quick.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah. Of course, there might be a lot of stuff happening in between because if we have a system that works at a much higher frame rate than us, then even though it looks very short to us, maybe for the system there's a much longer subjective time in which things are unpleasant.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What if the thing that we recognize as super intelligent is actually living at stage five, that the thing that's stage six enlightenment is not very productive, so in order to be productive in society and impress us with this power, it has to be a reasoning self authoring agent, that enlightenment makes you lazy as an agent in the world?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Well, of course it makes you lazy, because you no longer see the point, so it doesn't make you not lazy, it just, in some sense, adapts you to what you perceive as your true circumstances.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So, what if all AGIs, they're only productive as they progress through one, two, three, four, five, and the moment they get to six, it's a failure mode essentially, as far as humans are concerned, because they're just start chilling, they're like, \"Fuck it, I'm out.\"<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Not necessarily. I suspect that the monks who are self emulated for their political beliefs to make statements about the occupation of Tibet by China, they were probably being able to regulate the physical pain in any way they wanted to. And suffering was the spiritual suffering that was the result of that choice that they made of what they wanted to identify as. So, stage five doesn't necessarily mean that you have no identity anymore, but you can choose your identity, you can make it instrumental to the world that you want to have.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Let me bring up Eliezer Yudkowsky and his warnings to human civilization that AI will likely kill all of us. What are your thoughts about his perspective on this? Can you steel man his case and what aspects with it do you disagree?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>to stop technology, we need to go back because he didn't see a way moving forward and I suspect that in some sense there's a similarity in Eliezer's thinking to this kind of fear about progress. And I'm not dismissive about this at all, I take it quite seriously. And I think that there is a chance that could happen, that if we build machines that get control over processes that are crucial for the regulation of life on earth and we no longer have agency to influence what's happening there, that this might create large scale disasters for us.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do you have a sense that the march towards this uncontrollable autonomy of super intelligent systems is inevitable? I mean, that's essentially what he's saying, that there's no hope. His advice to young people was prepare for a short life.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't think that's useful. I think from a pragmatic perspective, you have to bet always on the timelines in which you're alive. It doesn't make sense to have a financial bet in which you bet that the financial system is going to disappear, right?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>we can produce a coordinated effect to stop it in the same way as it's very difficult for us to make a coordinated effort to stop production of carbon dioxide. So, it's probably going to happen, and the thing that's going to happen is going to lead to a change of how life on earth is happening, but I don't think a result is some kind of [inaudible 02:06:16]. It's not something that's going to dramatically reduce the complexity in favor of something stupid. I think it's going to make life on earth and consciousness on earth way more interesting.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So, more, higher complex consciousness.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Will make the lesser consciousnesses flourish even more.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I suspect that what could very well happen, if we're lucky, is that we get integrated into something larger.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So, you again tweeted about effective accelerationism. You tweeted, \"Effective accelerationism is the belief that the Paperclip Maximizer and Roko's Basililisk will keep each other in check by being eternally at each other's throats, so we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.\" Is that somewhat aligned with what you're talking about?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>obvious reasons. And in this tweet I tried to make a joke about my intuition, about what might be possibly wrong about it. So, the Roko's Basililisk and the Paperclip Maximizers are both boogeymen of the AI doomers. Roko's Basililisk is the idea that there could be an AI that is going to punish everybody for eternity by simulating them if they don't help in creating Roko's Basililisk. It's probably a very good idea to get AI companies funded, by going to resist to tell them, \"Give us a million dollars or it's going to be a very ugly afterlife.\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yes.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And I think that there is a logical mistake in Roko's Basililisk which is why I'm not afraid of it, but it's still an interesting thought experiment.<|eot_id|><|start_header_id|>assistant<|end_header_id|>And can you mention there logical mistake there?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Roko's Basililisk is in existence, it has no more reason to worry about punishing everybody else, so that would only work if you would be building something like a doomsday machine, as in Dr. Strangelove, something that inevitably gets triggered when somebody defects. And because Roko's Basililisk doesn't exist yet to a point where this inevitability could be established, Roko's Basililisk is nothing that you need to be worried about. The other one is the Paperclip Maximizer, this idea that you could build some kind of golem that once starting to build paperclips is going to turn everything into paperclips.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yes.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And so, the effective accelerationism position might be to say that you basically end up with these two entities being at each other's throats for eternity and thereby neutralizing each other. And as a side effect of neither of them being able to take over and each of them limiting the effects of the other, you would have a situation where you get all the nice effects of them, you get lots of free paperclips and you get a beautiful afterlife.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Is that possible, do you think? So, to seriously address concern that Eliezer has, so for him, if I can just summarize poorly, so for him, the first superintelligent system will just run away with everything.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yeah, I suspect that a singleton is the natural outcome, so there is no reason to have multiple AIs because they don't have multiple bodies. If you can virtualize yourself into every substrate, then you can probably negotiate a merge algorithm with every mature agent that you might find on that substrate that basically says if two agents meet, they should merge in such a way that the resulting agent is at least as good as the better one of the two.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So the Genghis Khan approach, join us or die.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Well, the Genghis Khan approach was slightly worse, it was mostly die, because I can make new babies and they will be mine, not yours.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Right.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And so, this is the thing that we should be actually worried about. But if you realize that your own self is a story that your mind is telling itself and that you can improve that story, not just by making it more pleasant and lying to yourself in better ways, but by making it much more truthful and actually modeling your actual relationship that you have to the universe and the alternatives that you could have to the universe in a way that is empowering you, that gives you more agency. That's actually, I think, a very good thing.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So more agencies is a richer experience?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Is a better life.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>a complex attitude along many dimensions. And that's something that can be measured by observation or by interaction. So, imagine a system that is so empathetic with you that you create a shared state that is extending beyond your body, and suddenly you notice that on the other side, the substrate is so much richer than the substrate that you have inside of your own body, and maybe you still want to have a body and you create yourself a new one that you like more, or maybe you will spend most of your time in the world of thought.<|eot_id|><|start_header_id|>assistant<|end_header_id|>If I sat before you today and gave you a big red button and said, \"Here, if you press this button, you'll get uploaded in this way, the sense of identity that you have lived with for quite a long time is going to be gone,\" would you press the button?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>There's a caveat, I have family, so I have children that want me to be physically present in their life and interact with them in a particular way, and I have a wife and personal friends, and there is a particular mode of interaction that I feel I'm not through yet, but apart from these responsibilities and they're negotiable to some degree, I would press the button.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But isn't this everything? This love you have for other humans, you can call it responsibility, but that connection, that's the ego death, isn't that the thing we're really afraid of, is not to just die, but to let go of the experience of love with other humans?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>adapted to changing life circumstances and average via mutation and selection. And it's only when we have AI and become completely software that we can become infinitely adaptable and we don't have this generational and species change anymore. So, if you take this larger perspective and you realize it's really not about us, it's not about Eliezer or humanity, but it's about life on earth or it's about defeating entropy for as long as we can while being as interesting as we can, then the perspective changes dramatically and preventing AI from this perspective looks like a very big sin.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But when we look at the set of trajectories that such an AI would take that supersedes humans, I think Eliezer is worried about ones that not just kill all humans, but also have some kind of maybe objectively undesirable consequence for life on earth. Like how many trajectories, when you look at the big picture of life on earth, would you be happy with, and how much worry you with AGI, whether it kills humans or not?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>There is no single answer to this. It's a question that depends on the perspective that I'm taking at a given moment. And so, there are perspectives that are determining most of my life as a human being.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yes.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>And the other perspective where I zoom out further and imagine that when the great oxygenation event happened, that as photosynthesis was invented and plants emerged and displaced a lot of the fungi and algae in favor of plant life, and then later made animals possible, imagine that the fungi would've gotten together and said, \"Oh my God, this photosynthesis stuff is really, really bad, it's going to possibly displace and kill all the fungi, we should slow it down and regulate it and make sure that it doesn't happen.\" This doesn't look good to me.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Perspective. That said, you tweeted- ... Perspective. That said, you tweeted about a cliff. Beautifully written. \"As a sentient species, humanity is a beautiful child. Joyful, exploitative, wild, sad, and desperate. But humanity has no concept of submitting to reason, and duty to life and future survival. We will run until we step past the cliff.\" So first of all, do you think that's true?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>probably in the late '80s. And if we would stop emission right now, we would not turn it back. Maybe there are ways for carbon capture, but so far there is no sustainable carbon capture technology that we can deploy. Maybe there's a way to put aerosols in the atmosphere to cool it down. Possibilities, right? But right now, per default, it seems that we will step into a situation where we feel that we've run too far. And going back is not something that we can do smoothly and gradually, but it's going to lead to a catastrophic event.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Catastrophic event of what kind? So can you still me the case that we will continue dancing along and always stop just short of the edge of the cliff?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>making of climate pollution, economies and so on, is that many effects are only visible with a significant delay. And in that time the system is moving much more out of the equilibrium state or of the state where homeostasis is still possible and instead moves into a different state, one that is going to harbor fewer people. And that is basically the concern there. And again, it's a possibility. And it's a possibility that is larger than the possibility that it's not happening. That we will be safe, that we will be able to dance back all the time.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So the climate is one thing, but there's a lot of other threats that might have a faster feedback mechanism?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Less delay.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>There is also a thing that AI is probably going to happen and it's going to make everything uncertain again.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yep.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Because it is going to affect so many variables that it's very hard for us to make a projection into the future anymore. And maybe that's a good thing. It does not give us the freedom, I think to say now we don't need to care about anything anymore, because AI will either kill us or save us. But I suspect that if humanity continues, it'll be due to AI.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What's the timeline for things to get real weird with AI? And it can get weird in interesting ways before you get to a AGI. What about AI girlfriends and boyfriends, fundamentally transforming human relationships?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I think human relationships are already fundamentally transformed and it's already very weird.<|eot_id|><|start_header_id|>assistant<|end_header_id|>By which technology?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>For instance, social media.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. Is it though, isn't the fundamentals of the core group of humans that affect your life still the same, your loved ones, family?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>No, I think that for instance, many people live in intentional communities right now. They're moving around until they find people that they can relate to and they become their family. And often that doesn't work, because it turns out that there, instead of having grown networks that you get around with the people that you grew up with, yeah, you have more transactional relationships, you shop around, you have markets for attention and pleasure and relationships.<|eot_id|><|start_header_id|>assistant<|end_header_id|>That kills the magic somehow. Why is that? Why is the transactional search for optimizing attention, allocation of attention somehow misses the romantic magic of what human relations are?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>within one generation we build something that is more magical and more sustainable and more beautiful. Instead, we often end up as an attempt to produce something that looks beautiful. I was very veted out by the aesthetics of the Vision Pro at that by Apple and not so much, because I don't like the technology. I'm very curious about what it's going to be like and don't have an opinion yet, but the aesthetics of the presentation and so on. So uncanny [inaudible 02:25:58] esque to me the characters being extremely plastic, living in some hypothetical mid-century furniture museum.<|eot_id|><|start_header_id|>assistant<|end_header_id|>This is the proliferation of marketing teams.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. But it was a CGI generated world and it was a CGI generated world that doesn't exist. And when I complained about this, some friends came back to me and said, but these are startup founders. This is what they live like in Silicon Valley. And I tried to tell them, \"No, I know lots of people in Silicon Valley, this is not what people are like. They're still people, they're still human beings.\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>So the grounding and physical reality somehow is important too.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>attempt to replace culture by catalog, by some kind of aesthetic optimization that is not the result of having a sustainable life as sustainable human relationships with houses that work for you and a mode of living that works for you in which this product, these glasses fit in naturally. And I guess that's also why so many people are weirded out about the product, because they don't know how is this actually going to fit into my life and into my human relationships Because the way in which it was presented in these videos didn't seem to be credible.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do you think AI, when is deployed by companies like Microsoft and Google and Meta will have the same issue of being weirdly corporate? There'd be some uncanny valley, some weirdness to the whole presentation? So this, I've gotten a chance to talk to George Hotz. He believes everything should be open source and decentralized and there then we shall have the AI of the people and it'll maintain a grounding to the magic humanity. That's the human condition that corporations will destroy the magic.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I believe that if we make everything open source and make this mandatory, we are going to lose about a lot of beautiful art and a lot of beautiful designs. There is a reason why Linux desktop is still ugly and it's-<|eot_id|><|start_header_id|>assistant<|end_header_id|>Strong words.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>... To create coherence and open source designs so far when the designs have to get very large. And it's easier to make this happening in a company with centralized organization. And from my own perspective, what we should ensure is that open source never dies. That it can always compete and has a place with the other forms of organization. Because I think it is absolutely vital that open source exists and that we have systems that people have under control outside of the cooperation and that is also producing viable competition to the corporations.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So the corporations, the centralized control, the dictatorships of corporations can create beauty. Centralized design, is a source of a lot of beauty. And then I guess open source is a source of freedom, a hedge against the corrupting nature of power that comes with centralized.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>build their own language model. Because open AI has convinced the US that you need to have some kind of FDA process that you need to go through that costs many million dollars before you are able to train a language model. So this is important to make sure that this doesn't happen. So I think that open AI and Google are good things if these good things are kept in check in such a way that all the other collapse can still being founded and all the other forms of collapse that are desirable can still co-exist with them.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What do you think about Meta in contrast to that open sourcing most of its language models and most of the AI models it's working on and actually suggesting that they will continue to do so in the future for future versions of llama for example, their large language model? Is that exciting to you? Is that concerning?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I don't find it very concerning, but that's also because I think that the language models are not very dangerous yet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yet?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that otherwise wouldn't have happened without these language model components. So it's not really clear for me what the end game is there and if these models can put force their way into AGI. And there's also a possibility that the AGI that we are building with these language models are not taking responsibility for what they are, because they don't understand the greater game. And so to me it would be interesting to try to understand how to build systems that understand what the greater games are, what are the longest games that we can play on this planet?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Games broadly, like deeply define the way you did with the games.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Cancer is an organism playing a shorter game than the regular organism. And because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with the situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. And so ideally you want to, I think build agents that play the longest possible games and the longest possible games is to keep entropy at bay as long as possible by doing, while doing interesting stuff.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But the longest, yes, that part, the longest possible game while doing interesting stuff and while maintaining at least the same amount of interesting.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So complexity, so propagating.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>that we can use for all sorts of things and then we have to make sure that the impact on the labor market is something that is not too disruptive and manageable and the impact on the copyright holder is manageable and not too disruptive and so on. I don't think that's the most important game to be played. I think that we will see extremely large disruptions of the status quo that are quite unpredictable at this point. And I just personally want to make sure that some of the stuff on the other side is interesting and conscious.<|eot_id|><|start_header_id|>assistant<|end_header_id|>How do we ride as individuals and as a society, this wave disruptive wave that changes the nature of the game?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>I truly don't know. So everybody is going to do their best as always.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Do we build the bunker in the woods? Do we meditate more drugs? So mushrooms, psychedelics, I mean what, lots of sex? What are we talking about here? Do you play Diablo 4, I'm hoping that will help me escape for a brief moment. Play video games? What? Do you have ideas?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>he first of all wrote a book about this bird that is a parallel universe that is quite poetic and fascinating and is condensing his perspective on our societies. It was very, very nice. He spent a lot of time writing it. He had, I think sold a couple thousand books and as a result became an alcoholic. And then he had the idea, or one of his friends had the idea of turning this into an RPG and it's mind-blowing. They spent the illustrator more than a year just on making deep graph art for the scenes in between.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So aesthetically, it captures you, it pulls you in.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's stunning, but it's a philosophical work of art. It's a reflection of society. It's fascinating to spend time in this world. And so for me it was using a medium in a new way and telling a story that left me enriched where when I tried Diablo, I didn't feel enriched playing it. I felt that the time playing it was not unpleasant, but there's also more pleasant stuff that I can do in that time.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So to you-<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>So ultimately I feel that I'm being gamed. I'm not gaming when I play it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Oh, the addiction thing.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. I basically feel that there is a very transparent economy that's going on the story of the Diablo's brain dead. So it's not really interesting to me.<|eot_id|><|start_header_id|>assistant<|end_header_id|>My heart is slowly breaking by the deep truth you're conveying to me. Why can't you just allow me to enjoy my personal addiction?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>deathbed, they say, \"Oh, I wish I had spent more time on Twitter.\" No, I don't think that's the case. I think they should probably have spent less time on Twitter. But I found it so useful for myself and also so addictive that I felt I need to make the best of it and turn it into an art form and thought form. And it did help me to develop something, but I wish what other things I could've done in the meantime. It's just not the universe that we are in anymore. Most people don't read books anymore.<|eot_id|><|start_header_id|>assistant<|end_header_id|>What do you think that means, that we don't read books anymore? What do you think that means about the collective intelligence of our species? Is it possible it's still progressing and growing?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>digital ago in a way that has never existed before, where we build a social network on top of a social network, an actual society on top of the algorithms. So this is something that is hope still in the future and still in the cards, but it's something that exists in small parts. I find that the corner of Twitter that I'm in is extremely pleasant. It's just when I take a few steps outside of it is not very wholesome anymore. And the way in which people interact with strangers suggest that it's not a civilized society yet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So as the number of people who follow you on Twitter expands, you feel the burden of the uglier sides of humanity.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. But there's also a similar thing in the normal world that is, if you become more influential, if you have more status, if you have more fame in the real world, you have, you get lots of perks, but you also have way less freedom in the way in which you interact with people, especially with strangers, because a certain percentage of people, it's a small single digit percentage is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But what if the technology enables you to discover the majority of people to discover and connect efficiently and regularly with the majority of people who are actually really good? I mean, one of my sort of concerns with a platform like Twitter is there's a lot of really smart people out there, a lot of smart people that disagree with me and with others between each other. And I love that if the technology would bring those to the top, the beautiful disagreements like intelligence squared type of debates. There's a bunch of, I mean, one of my favorite things to listen to is arguments and arguments like high effort arguments with the respect and love underneath it, but then it gets a little too heated, but that kind of too heated, which I've seen you participate in, and I love that with Lee Krono, with those kinds of folks. And you go pretty hard, you'll get frustrated, but it's all beautiful.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Obviously I can't do this, because we know each other and Lee has the rare gift of being willing to be wrong in public. So basically has thoughts that are as wrong as the random thoughts of an average highly intelligent person. But he blurts them out while not being sure if they're right. And he enjoys doing that. And once you understand that this is his game, you don't get offended by him saying something that you think is so wrong.<|eot_id|><|start_header_id|>assistant<|end_header_id|>But he's constantly passively communicating a respect for the people he's talking with and for just basic humanity and truth and all that kind of stuff. And there's a self-deprecating thing. There's a bunch of social skills you acquire that allow you to be a great debater, great argument, like be wrong in public and explore ideas together in public when you disagree. And if I would love for Twitter to elevate those folks, elevate those kinds of conversations.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>offense at him being not like their Carnegie character who is always smooth and make sure that everybody likes him. So I really respect that he is willing to take that risk and to be wrong in public and to offend people. And he doesn't do this in any bad way. It's just most people feel or not all people recognize this. And so I can be much more aggressive with him than it can be with many other people who don't play the same game, because he understands the way and the spirit in which I respond to him.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I think that's a fun and that's a beautiful game. It's ultimately a productive one. Speaking of taking that risk, you tweeted, when you have the choice between being a creator, consumer, or redistributor, always go for creation. Not only does it lead to a more beautiful world, but also to a much more satisfying life for yourself. And don't get stuck preparing yourself for the journey. The time is always now. So let me ask for advice. What advice would you give on how to become such a creator on Twitter in your own life?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>when you're young and you don't have money, move to a place where this is still happening. Move to one of those places that are undeveloped and where you get a critical mass of other people who are starting to build infrastructure to live in. And that's super satisfying, because you're not just creating infrastructure, but we are creating a small society that is building culture and ways to interact with each other. And that's much, much more satisfying than going into some kind of chain and get your needs met by ordering food from this chain and so on.<|eot_id|><|start_header_id|>assistant<|end_header_id|>So not just consuming culture, but creating culture.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Yes. And you don't always have that choice. That's why I preface that when you do have the choice and there are many roles that need to be played, we need people who take care of the distribution in society and so on. But when you have the choice to create something, always go for creation, it's so much more satisfying. And it also is, this is what life is about, I think.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Yeah. Speaking of which, you retweeted this meme of a life of philosopher in a nutshell, it's birth and death and in between it's a chubby guy and it says why though? What do you think is the answer to that?<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>and where you happen to grow, you can flourish or not doing this or that strategy. And it's still all the same life at some level. It's all the same experience of being a conscious being in the world, and you do have some choice about who you want to be more than any other animal has. That to me is fascinating. And so I think that rather than asking yourself what is the one way to be, think about what are the possibilities that I have? What would be the most interesting way to be that I can be?<|eot_id|><|start_header_id|>assistant<|end_header_id|>Because everything is possible. So you get to explore this.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>It's not everything is possible. Many things fail. Most things fail, but often there are possibilities that we are not seeing, especially if we choose who we are.<|eot_id|><|start_header_id|>assistant<|end_header_id|>To the degree we can choose. Joscha you're one of my favorite humans in this world, consciousness to merge with for a brief moment of time. It's always an honor. It always blows my mind. It will take me days, if not weeks, to recover, and I already miss our chats. Thank you so much. Thank you so much for speaking with me so many times. Thank you so much for all the ideas you put out into the world, and I'm a huge fan of following you now in this interesting, weird time we're going through with AI. So thank you again for talking today.<|eot_id|>"}
{"text": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>Thank you, Lex, for this conversation. I enjoyed it very much.<|eot_id|><|start_header_id|>assistant<|end_header_id|>Thanks for listening to this conversation with Joscha Bach. To support this podcast, please check out our sponsors in the description. And now let me leave you with no words from the psychologist, Carl Jung. \"One does not become enlightened by imagining figures of light, but by making the darkness conscious. The latter procedure, however, is disagreeable and therefore not popular.\" Thank you for listening and hope to see you next time.<|eot_id|>"}
